{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from layer import KernelConv2d\n",
    "%matplotlib inline\n",
    "def mkdirs(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kervolution LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(KNNet,self).__init__()\n",
    "        self.conv1=KernelConv2d(1,10,5)\n",
    "        print(self.conv1)\n",
    "        self.bn1=nn.BatchNorm2d(10)\n",
    "        self.conv2=KernelConv2d(10,20,5)\n",
    "        self.bn2=nn.BatchNorm2d(20)\n",
    "        self.conv2_drop=nn.Dropout2d()\n",
    "        self.fc1=nn.Linear(320,50)\n",
    "        self.fc2=nn.Linear(50,10)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(F.max_pool2d(self.conv1(x),2))\n",
    "        x=self.bn1(x)\n",
    "        x=F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
    "        x=self.bn2(x)\n",
    "        x=x.view(-1,320)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.dropout(x,training=self.training)\n",
    "        x=F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "train_loader=torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"data\",train=True,download=True,transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "            ])),batch_size=128,shuffle=True)\n",
    "test_loader=torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"data\",train=False,download=True,transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "            ])),batch_size=128,shuffle=False\n",
    ")\n",
    "attack_test_loader=torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\"data\",train=False,download=True,transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "            ])),batch_size=1,shuffle=False\n",
    ")\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelConv2d(\n",
      "  1, 10, kernel_size=(5, 5), stride=(1, 1), bias=False\n",
      "  (kernel_fn): PolynomialKernel()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNNet(\n",
       "  (conv1): KernelConv2d(\n",
       "    1, 10, kernel_size=(5, 5), stride=(1, 1), bias=False\n",
       "    (kernel_fn): PolynomialKernel()\n",
       "  )\n",
       "  (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): KernelConv2d(\n",
       "    10, 20, kernel_size=(5, 5), stride=(1, 1), bias=False\n",
       "    (kernel_fn): PolynomialKernel()\n",
       "  )\n",
       "  (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_drop): Dropout2d(p=0.5)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "knn=KNNet().to(device)\n",
    "knn.train(mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuray(pred,true):\n",
    "    pred_idx=pred.argmax(dim=1).detach().cpu().numpy()\n",
    "    tmp=pred_idx==true.cpu().numpy()\n",
    "    return sum(tmp)/len(pred_idx)\n",
    "def train(m,out_dir):\n",
    "    iter_loss=[]\n",
    "    train_losses=[]\n",
    "    test_losses=[]\n",
    "    iter_loss_path=os.path.join(out_dir,\"iter_loss.csv\")\n",
    "    epoch_loss_path=os.path.join(out_dir,\"epoch_loss.csv\")\n",
    "    nb_epochs=20\n",
    "    last_loss=99999\n",
    "    mkdirs(os.path.join(out_dir,\"models\"))\n",
    "    optimizer=optim.SGD(m.parameters(),lr=0.003,momentum=0.9)\n",
    "    for epoch in range(nb_epochs):\n",
    "        train_loss=0.\n",
    "        train_acc=0.\n",
    "        m.train(mode=True)\n",
    "        for data,target in train_loader:\n",
    "            data,target=data.to(device),target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output=m(data)\n",
    "            loss=criterion(output,target)\n",
    "            loss_value=loss.item()\n",
    "            iter_loss.append(loss_value)\n",
    "            train_loss+=loss_value\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc=compute_accuray(output,target)\n",
    "            train_acc+=acc\n",
    "        train_losses.append(train_loss/len(train_loader))\n",
    "        \n",
    "        test_loss=0.\n",
    "        test_acc=0.\n",
    "        m.train(mode=False)\n",
    "        for data,target in test_loader:\n",
    "            data,target=data.to(device),target.to(device)\n",
    "            output=m(data)\n",
    "            loss=criterion(output,target)\n",
    "            loss_value=loss.item()\n",
    "            iter_loss.append(loss_value)\n",
    "            test_loss+=loss_value\n",
    "            acc=compute_accuray(output,target)\n",
    "            test_acc+=acc\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "        print(\"Epoch {}: train loss is {}, train accuracy is {}; test loss is {}, test accuracy is {}\".\n",
    "              format(epoch,round(train_loss/len(train_loader),2),\n",
    "                     round(train_acc/len(train_loader),2),\n",
    "                     round(test_loss/len(test_loader),2),\n",
    "                     round(test_acc/len(test_loader),2)))        \n",
    "        if test_loss/len(test_loader)<last_loss:      \n",
    "            save_model_path=os.path.join(out_dir,\"models\",\"best_model.tar\".format(epoch))\n",
    "            torch.save({\n",
    "                    \"model\":m.state_dict(),\n",
    "                    \"optimizer\":optimizer.state_dict()\n",
    "                },save_model_path)\n",
    "            last_loss=test_loss/len(test_loader)\n",
    "        \n",
    "    df=pd.DataFrame()\n",
    "    df[\"iteration\"]=np.arange(0,len(iter_loss))\n",
    "    df[\"loss\"]=iter_loss\n",
    "    df.to_csv(iter_loss_path,index=False)\n",
    "    \n",
    "    df=pd.DataFrame()\n",
    "    df[\"epoch\"]=np.arange(0,nb_epochs)\n",
    "    df[\"train_loss\"]=train_losses\n",
    "    df[\"test_loss\"]=test_losses\n",
    "    df.to_csv(epoch_loss_path,index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss is 1.79, train accuracy is 0.42; test loss is 0.6, test accuracy is 0.89\n",
      "Epoch 1: train loss is 0.67, train accuracy is 0.8; test loss is 0.2, test accuracy is 0.95\n",
      "Epoch 2: train loss is 0.44, train accuracy is 0.87; test loss is 0.13, test accuracy is 0.96\n",
      "Epoch 3: train loss is 0.35, train accuracy is 0.9; test loss is 0.1, test accuracy is 0.97\n",
      "Epoch 4: train loss is 0.3, train accuracy is 0.91; test loss is 0.08, test accuracy is 0.97\n",
      "Epoch 5: train loss is 0.27, train accuracy is 0.92; test loss is 0.08, test accuracy is 0.98\n",
      "Epoch 6: train loss is 0.24, train accuracy is 0.93; test loss is 0.07, test accuracy is 0.98\n",
      "Epoch 7: train loss is 0.22, train accuracy is 0.94; test loss is 0.07, test accuracy is 0.98\n",
      "Epoch 8: train loss is 0.21, train accuracy is 0.94; test loss is 0.06, test accuracy is 0.98\n",
      "Epoch 9: train loss is 0.19, train accuracy is 0.94; test loss is 0.06, test accuracy is 0.98\n",
      "Epoch 10: train loss is 0.19, train accuracy is 0.94; test loss is 0.05, test accuracy is 0.98\n",
      "Epoch 11: train loss is 0.18, train accuracy is 0.95; test loss is 0.05, test accuracy is 0.98\n",
      "Epoch 12: train loss is 0.17, train accuracy is 0.95; test loss is 0.05, test accuracy is 0.98\n",
      "Epoch 13: train loss is 0.17, train accuracy is 0.95; test loss is 0.05, test accuracy is 0.99\n",
      "Epoch 14: train loss is 0.16, train accuracy is 0.95; test loss is 0.05, test accuracy is 0.99\n",
      "Epoch 15: train loss is 0.16, train accuracy is 0.95; test loss is 0.04, test accuracy is 0.99\n",
      "Epoch 16: train loss is 0.15, train accuracy is 0.96; test loss is 0.04, test accuracy is 0.99\n",
      "Epoch 17: train loss is 0.15, train accuracy is 0.96; test loss is 0.04, test accuracy is 0.99\n",
      "Epoch 18: train loss is 0.14, train accuracy is 0.96; test loss is 0.04, test accuracy is 0.99\n",
      "Epoch 19: train loss is 0.14, train accuracy is 0.96; test loss is 0.05, test accuracy is 0.99\n"
     ]
    }
   ],
   "source": [
    "train(knn,\"lenet-knn-cp0.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
